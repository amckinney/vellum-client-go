// This file was auto-generated by Fern from our API Definition.

package api

import (
	json "encoding/json"
	fmt "fmt"
	core "github.com/vellum-ai/vellum-client-go/core"
	time "time"
)

type ModelVersionCompilePromptRequestRequest struct {
	// Key/value pairs for each variable found within the model version's prompt template.
	InputValues map[string]interface{} `json:"input_values,omitempty"`
}

type ModelVersionCompilePromptResponse struct {
	// Information about the compiled prompt.
	Prompt *ModelVersionCompiledPrompt `json:"prompt,omitempty"`

	_rawJSON json.RawMessage
}

func (m *ModelVersionCompilePromptResponse) UnmarshalJSON(data []byte) error {
	type unmarshaler ModelVersionCompilePromptResponse
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*m = ModelVersionCompilePromptResponse(value)
	m._rawJSON = json.RawMessage(data)
	return nil
}

func (m *ModelVersionCompilePromptResponse) String() string {
	if len(m._rawJSON) > 0 {
		if value, err := core.StringifyJSON(m._rawJSON); err == nil {
			return value
		}
	}
	if value, err := core.StringifyJSON(m); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", m)
}

type ModelVersionRead struct {
	// Vellum-generated ID that uniquely identifies this model version.
	Id string `json:"id"`
	// Timestamp of when this model version was created.
	Created time.Time `json:"created"`
	// Human-friendly name for this model version.
	Label string `json:"label"`
	// Which LLM provider this model version is associated with.
	//
	// * `ANTHROPIC` - Anthropic
	// * `COHERE` - Cohere
	// * `GOOGLE` - Google
	// * `HOSTED` - Hosted
	// * `MOSAICML` - MosaicML
	// * `OPENAI` - OpenAI
	// * `HUGGINGFACE` - HuggingFace
	// * `MYSTIC` - Mystic
	// * `PYQ` - Pyq
	Provider ProviderEnum `json:"provider,omitempty"`
	// The unique id of this model version as it exists in the above provider's system.
	ExternalId string `json:"external_id"`
	// Configuration used to build this model version.
	BuildConfig *ModelVersionBuildConfig `json:"build_config,omitempty"`
	// Configuration used to execute this model version.
	ExecConfig *ModelVersionExecConfig     `json:"exec_config,omitempty"`
	Status     *ModelVersionReadStatusEnum `json:"status,omitempty"`

	_rawJSON json.RawMessage
}

func (m *ModelVersionRead) UnmarshalJSON(data []byte) error {
	type unmarshaler ModelVersionRead
	var value unmarshaler
	if err := json.Unmarshal(data, &value); err != nil {
		return err
	}
	*m = ModelVersionRead(value)
	m._rawJSON = json.RawMessage(data)
	return nil
}

func (m *ModelVersionRead) String() string {
	if len(m._rawJSON) > 0 {
		if value, err := core.StringifyJSON(m._rawJSON); err == nil {
			return value
		}
	}
	if value, err := core.StringifyJSON(m); err == nil {
		return value
	}
	return fmt.Sprintf("%#v", m)
}
